{"cells":[{"cell_type":"markdown","metadata":{"id":"KbDHl75NIsK0"},"source":["### Spark Moive Recommendation\n","In this notebook, Alternating Least Squares (ALS) algorithm will be used with Spark APIs to predict the ratings for the movies in [MovieLens small dataset](https://grouplens.org/datasets/movielens/latest/)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":68779,"status":"ok","timestamp":1669903914459,"user":{"displayName":"Nikhil Dhumale","userId":"00177140792561608785"},"user_tz":-330},"id":"R-GO29ebIsK4","outputId":"94ccf0cb-806f-492a-cba8-37788c837375"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyspark\n","  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n","\u001b[K     |████████████████████████████████| 281.4 MB 43 kB/s \n","\u001b[?25hCollecting py4j==0.10.9.5\n","  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n","\u001b[K     |████████████████████████████████| 199 kB 55.3 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=bfb0bf75b98f9ce270e23bf66775d3b416533dab3df6db22f1b7d1797da523bf\n","  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mlflow\n","  Downloading mlflow-2.0.1-py3-none-any.whl (16.5 MB)\n","\u001b[K     |████████████████████████████████| 16.5 MB 4.9 MB/s \n","\u001b[?25hRequirement already satisfied: Flask<3 in /usr/local/lib/python3.8/dist-packages (from mlflow) (1.1.4)\n","Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.8/dist-packages (from mlflow) (6.0)\n","Requirement already satisfied: numpy<2 in /usr/local/lib/python3.8/dist-packages (from mlflow) (1.21.6)\n","Collecting alembic<2\n","  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n","\u001b[K     |████████████████████████████████| 209 kB 51.1 MB/s \n","\u001b[?25hRequirement already satisfied: entrypoints<1 in /usr/local/lib/python3.8/dist-packages (from mlflow) (0.4)\n","Collecting querystring-parser<2\n","  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n","Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.8/dist-packages (from mlflow) (3.2.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.8/dist-packages (from mlflow) (7.1.2)\n","Requirement already satisfied: pytz<2023 in /usr/local/lib/python3.8/dist-packages (from mlflow) (2022.6)\n","Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from mlflow) (0.4.3)\n","Requirement already satisfied: scipy<2 in /usr/local/lib/python3.8/dist-packages (from mlflow) (1.7.3)\n","Requirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.8/dist-packages (from mlflow) (1.5.0)\n","Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.8/dist-packages (from mlflow) (1.0.2)\n","Collecting gunicorn<21\n","  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n","\u001b[K     |████████████████████████████████| 79 kB 7.4 MB/s \n","\u001b[?25hRequirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.8/dist-packages (from mlflow) (2.11.3)\n","Collecting databricks-cli<1,>=0.8.7\n","  Downloading databricks-cli-0.17.3.tar.gz (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 5.0 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata!=4.7.0,<6,>=3.7.0 in /usr/local/lib/python3.8/dist-packages (from mlflow) (4.13.0)\n","Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.8/dist-packages (from mlflow) (2.23.0)\n","Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.8/dist-packages (from mlflow) (3.4.1)\n","Requirement already satisfied: packaging<22 in /usr/local/lib/python3.8/dist-packages (from mlflow) (21.3)\n","Requirement already satisfied: pandas<2 in /usr/local/lib/python3.8/dist-packages (from mlflow) (1.3.5)\n","Collecting shap<1,>=0.40\n","  Downloading shap-0.41.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (575 kB)\n","\u001b[K     |████████████████████████████████| 575 kB 44.4 MB/s \n","\u001b[?25hCollecting gitpython<4,>=2.1.0\n","  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 66.8 MB/s \n","\u001b[?25hRequirement already satisfied: sqlalchemy<2,>=1.4.0 in /usr/local/lib/python3.8/dist-packages (from mlflow) (1.4.44)\n","Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.8/dist-packages (from mlflow) (3.19.6)\n","Collecting docker<7,>=4.0.0\n","  Downloading docker-6.0.1-py3-none-any.whl (147 kB)\n","\u001b[K     |████████████████████████████████| 147 kB 56.7 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow<11,>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from mlflow) (9.0.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from alembic<2->mlflow) (5.10.0)\n","Collecting Mako\n","  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 7.1 MB/s \n","\u001b[?25hCollecting pyjwt>=1.7.0\n","  Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n","Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.8/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.8.10)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.15.0)\n","Collecting websocket-client>=0.32.0\n","  Downloading websocket_client-1.4.2-py3-none-any.whl (55 kB)\n","\u001b[K     |████████████████████████████████| 55 kB 3.5 MB/s \n","\u001b[?25hCollecting urllib3>=1.26.0\n","  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n","\u001b[K     |████████████████████████████████| 140 kB 59.7 MB/s \n","\u001b[?25hCollecting requests<3,>=2.17.3\n","  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from Flask<3->mlflow) (1.0.1)\n","Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from Flask<3->mlflow) (1.1.0)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 1.4 MB/s \n","\u001b[?25hCollecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.8/dist-packages (from gunicorn<21->mlflow) (57.4.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata!=4.7.0,<6,>=3.7.0->mlflow) (3.10.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.0.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow) (1.4.4)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib<4->mlflow) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.17.3->mlflow) (2022.9.24)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.17.3->mlflow) (2.10)\n","Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.17.3->mlflow) (2.1.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<2->mlflow) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<2->mlflow) (1.2.0)\n","Collecting slicer==0.0.7\n","  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n","Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.8/dist-packages (from shap<1,>=0.40->mlflow) (4.64.1)\n","Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from shap<1,>=0.40->mlflow) (0.56.4)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.8/dist-packages (from sqlalchemy<2,>=1.4.0->mlflow) (2.0.1)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->shap<1,>=0.40->mlflow) (0.39.1)\n","Building wheels for collected packages: databricks-cli\n","  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for databricks-cli: filename=databricks_cli-0.17.3-py3-none-any.whl size=139102 sha256=64863814d4bcc77b691dba0df24f77b7c996eeda3b2ce6c8be4699e3ceada70c\n","  Stored in directory: /root/.cache/pip/wheels/58/40/7c/d021d51dac18bfd095fb6837572ad2e6f1a34d221f4b1d976b\n","Successfully built databricks-cli\n","Installing collected packages: urllib3, smmap, websocket-client, slicer, requests, pyjwt, Mako, gitdb, shap, querystring-parser, gunicorn, gitpython, docker, databricks-cli, alembic, mlflow\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","Successfully installed Mako-1.2.4 alembic-1.8.1 databricks-cli-0.17.3 docker-6.0.1 gitdb-4.0.10 gitpython-3.1.29 gunicorn-20.1.0 mlflow-2.0.1 pyjwt-2.6.0 querystring-parser-1.2.4 requests-2.28.1 shap-0.41.0 slicer-0.0.7 smmap-5.0.0 urllib3-1.26.13 websocket-client-1.4.2\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import math\n","%matplotlib inline\n","\n","!pip install pyspark\n","!pip install mlflow\n","#dbutils.library.installPyPI(\"mlflow\")\n","#dbutils.library.restartPython()\n","import mlflow"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"_HGwMAkOIsK6"},"outputs":[],"source":["import os\n","os.environ[\"PYSPARK_PYTHON\"] = \"python3\""]},{"cell_type":"markdown","metadata":{"id":"j88DHAA-IsK7"},"source":["## Part1: Data ETL and Data Exploration"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"QKK-QYTkIsK7"},"outputs":[],"source":["from pyspark.sql import SparkSession\n","spark = SparkSession \\\n","    .builder \\\n","    .appName(\"moive analysis\") \\\n","    .config(\"spark.some.config.option\", \"some-value\") \\\n","    .getOrCreate()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":292169,"status":"ok","timestamp":1669904214713,"user":{"displayName":"Nikhil Dhumale","userId":"00177140792561608785"},"user_tz":-330},"id":"PRVf-eL2JRcI","outputId":"5f6d1c57-8f0c-4eb7-eb0f-75d84fde2de0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive');\n","DATA_PATH = \"drive/My Drive/Big Data Project/Data/MovieLens27M/\""]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"fZJMvzJJIsK7"},"outputs":[],"source":["movies_df = spark.read.load(DATA_PATH + \"movies.csv\", format='csv', header = True)\n","ratings_df = spark.read.load(DATA_PATH + \"ratings.csv\", format='csv', header = True)\n","links_df = spark.read.load(DATA_PATH + \"links.csv\", format='csv', header = True)\n","tags_df = spark.read.load(DATA_PATH + \"tags.csv\", format='csv', header = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1407,"status":"ok","timestamp":1669904228843,"user":{"displayName":"Nikhil Dhumale","userId":"00177140792561608785"},"user_tz":-330},"id":"nFBpUVEDIsK8","outputId":"827d07cb-3ec2-4c6c-c610-00dea4201a21"},"outputs":[{"data":{"text/plain":["pyspark.sql.dataframe.DataFrame"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["type(movies_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":999,"status":"ok","timestamp":1669904229838,"user":{"displayName":"Nikhil Dhumale","userId":"00177140792561608785"},"user_tz":-330},"id":"tovgfLJCIsK8","outputId":"e7c61354-279e-467c-85e4-c75ac36ebe48"},"outputs":[{"data":{"text/plain":["58098"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["movies_df.count()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1669904229839,"user":{"displayName":"Nikhil Dhumale","userId":"00177140792561608785"},"user_tz":-330},"id":"WNXxDsjaIsK8","outputId":"40f4a106-be2a-4a6c-e70e-d13e84267547"},"outputs":[{"data":{"text/plain":["DataFrame[movieId: string, title: string, genres: string]"]},"metadata":{},"output_type":"display_data"}],"source":["#movies_df.show(5)\n","\n","movies_df.createOrReplaceTempView(\"movies_df\")\n","\n","display (spark.sql(\"SELECT * FROM movies_df limit 5\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1669904230665,"user":{"displayName":"Nikhil Dhumale","userId":"00177140792561608785"},"user_tz":-330},"id":"kEXk_TVBIsK9","outputId":"366f1a49-92ac-428a-80e2-c43a75273fe6"},"outputs":[{"data":{"text/plain":["DataFrame[userId: string, movieId: string, rating: string, timestamp: string]"]},"metadata":{},"output_type":"display_data"}],"source":["#ratings_df.show(5)\n","\n","ratings_df.createOrReplaceTempView(\"ratings_df\")\n","\n","display (spark.sql(\"SELECT * FROM ratings_df limit 5\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":225},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1669904230667,"user":{"displayName":"Nikhil Dhumale","userId":"00177140792561608785"},"user_tz":-330},"id":"uhZu7WStIsK9","outputId":"85939d7a-170a-4c13-b9dd-478a4e5cabfb"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+-------+------+\n","|movieId| imdbId|tmdbId|\n","+-------+-------+------+\n","|      1|0114709|   862|\n","|      2|0113497|  8844|\n","|      3|0113228| 15602|\n","|      4|0114885| 31357|\n","|      5|0113041| 11862|\n","+-------+-------+------+\n","only showing top 5 rows\n","\n"]},{"data":{"text/plain":["DataFrame[movieId: string, imdbId: string, tmdbId: string]"]},"metadata":{},"output_type":"display_data"}],"source":["links_df.show(5)\n","\n","links_df.createOrReplaceTempView(\"links_df\")\n","\n","display (spark.sql(\"SELECT * FROM links_df limit 5\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1669904230668,"user":{"displayName":"Nikhil Dhumale","userId":"00177140792561608785"},"user_tz":-330},"id":"FC_OiVvEIsK-","outputId":"174cf01e-0f75-429d-f064-b05bc23a237a"},"outputs":[{"data":{"text/plain":["DataFrame[userId: string, movieId: string, tag: string, timestamp: string]"]},"metadata":{},"output_type":"display_data"}],"source":["#tags_df.show(5)\n","\n","tags_df.createOrReplaceTempView(\"tags_df\")\n","\n","display (spark.sql(\"SELECT * FROM tags_df limit 5\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":74531,"status":"ok","timestamp":1669904305184,"user":{"displayName":"Nikhil Dhumale","userId":"00177140792561608785"},"user_tz":-330},"id":"ytEBw1etIsK_","outputId":"12383020-af7e-46c5-a584-65b1aba53176"},"outputs":[{"name":"stdout","output_type":"stream","text":["For the users that rated movies and the movies that were rated:\n","Minimum number of ratings per user is 1\n","Minimum number of ratings per movie is 1\n"]}],"source":["tmp1 = ratings_df.groupBy(\"userID\").count().toPandas()['count'].min()\n","tmp2 = ratings_df.groupBy(\"movieId\").count().toPandas()['count'].min()\n","print('For the users that rated movies and the movies that were rated:')\n","print('Minimum number of ratings per user is {}'.format(tmp1))\n","print('Minimum number of ratings per movie is {}'.format(tmp2))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":68185,"status":"ok","timestamp":1669904373348,"user":{"displayName":"Nikhil Dhumale","userId":"00177140792561608785"},"user_tz":-330},"id":"En4ApvYlIsLA","outputId":"df9866d7-62e4-4aa4-8938-0375a0d1a298"},"outputs":[{"name":"stdout","output_type":"stream","text":["10155 out of 53889 movies are rated by only one user\n"]}],"source":["tmp1 = sum(ratings_df.groupBy(\"movieId\").count().toPandas()['count'] == 1)\n","tmp2 = ratings_df.select('movieId').distinct().count()\n","print('{} out of {} movies are rated by only one user'.format(tmp1, tmp2))"]},{"cell_type":"markdown","metadata":{"id":"Qw3dmRICIsLA"},"source":["## Part 1: Spark SQL and OLAP"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1669904373349,"user":{"displayName":"Nikhil Dhumale","userId":"00177140792561608785"},"user_tz":-330},"id":"Gc1sq3xeIsLB","outputId":"937de51c-e5d4-4f46-fcc6-4b140bd0e9e4"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.8/dist-packages/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n","  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"]}],"source":["movies_df.registerTempTable(\"movies\")\n","ratings_df.registerTempTable(\"ratings\")\n","links_df.registerTempTable(\"links\")\n","tags_df.registerTempTable(\"tags\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"DxzIgU0wIsLB"},"source":["### The number of Users"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1669904373350,"user":{"displayName":"Nikhil Dhumale","userId":"00177140792561608785"},"user_tz":-330},"id":"Wd56Y_TRIsLB","outputId":"8c9eaf8f-1d74-4dc0-ddb1-215950e2604b"},"outputs":[{"data":{"text/plain":["DataFrame[num_users: bigint]"]},"metadata":{},"output_type":"display_data"}],"source":["# %sql\n","num_users = spark.sql(\"SELECT count (distinct userID) as num_users FROM ratings\")\n","display(num_users)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30839,"status":"ok","timestamp":1669904404180,"user":{"displayName":"Nikhil Dhumale","userId":"00177140792561608785"},"user_tz":-330},"id":"7sXBwnhzIsLC","outputId":"cc7a1046-cfcb-4cb8-8228-9670556ea2bd"},"outputs":[{"data":{"text/plain":["283228"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["ratings_df.select(\"userId\").distinct().count()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1669904404181,"user":{"displayName":"Nikhil Dhumale","userId":"00177140792561608785"},"user_tz":-330},"id":"aSm4nCgwIsLC","outputId":"53bf11b8-4cda-4348-d561-199bd4971670"},"outputs":[{"data":{"text/plain":["pyspark.sql.dataframe.DataFrame"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["type(ratings_df.select(\"userId\"))"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"0lgzHfPmIsLC"},"source":["###  The number of Movies"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1669904404182,"user":{"displayName":"Nikhil Dhumale","userId":"00177140792561608785"},"user_tz":-330},"id":"JIaze2iUIsLD","outputId":"11e012ad-6696-4005-dc90-704d6a8be54c"},"outputs":[{"data":{"text/plain":["DataFrame[num_movies: bigint]"]},"metadata":{},"output_type":"display_data"}],"source":["#%sql \n","num_movies = spark.sql(\"SELECT count (distinct movieID) as num_movies FROM movies\")\n","display(num_movies)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1426,"status":"ok","timestamp":1669904405598,"user":{"displayName":"Nikhil Dhumale","userId":"00177140792561608785"},"user_tz":-330},"id":"d4Kp0crzIsLD","outputId":"c4e70c26-1fd9-416d-bb0b-6e0a05b245e3"},"outputs":[{"data":{"text/plain":["58098"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["movies_df.select('movieID').distinct().count()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1669904405599,"user":{"displayName":"Nikhil Dhumale","userId":"00177140792561608785"},"user_tz":-330},"id":"AOKLoDA5IsLD","outputId":"abc76ab6-8c20-4d53-d33f-ea818e752c8c"},"outputs":[{"data":{"text/plain":["58098"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["movies_df.select('movieID').count()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"IKGptyZ9IsLE"},"source":["###  How many movies are rated by users? List movies not rated before"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30362,"status":"ok","timestamp":1669904435956,"user":{"displayName":"Nikhil Dhumale","userId":"00177140792561608785"},"user_tz":-330},"id":"dfax6X5MIsLE","outputId":"abcd4751-ec26-4f1d-af3b-ad049ca81652"},"outputs":[{"name":"stdout","output_type":"stream","text":["How many movies are rated by users? 53889\n"]}],"source":["rated_by_users = ratings_df.select('movieID').distinct().count()\n","print('How many movies are rated by users?', rated_by_users)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130},"executionInfo":{"elapsed":48,"status":"error","timestamp":1669904435958,"user":{"displayName":"Nikhil Dhumale","userId":"00177140792561608785"},"user_tz":-330},"id":"Jl0rcTfHIsLE","outputId":"ef171f8a-a5e5-4ad6-f41b-68359b981edd"},"outputs":[],"source":["%sql \n","SELECT movies.title, movies.genres, ratings.rating FROM movies left JOIN ratings ON ratings.movieId = movies.movieID WHERE ratings.rating IS null LIMIT 10"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"1jk9n3wuIsLE"},"source":["### List Movie Genres"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"USaCC-_kIsLF"},"outputs":[],"source":["%sql\n","SELECT DISTINCT(genres) FROM movies LIMIT 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7PbTV6LEIsLF"},"outputs":[],"source":["%sql\n","SELECT SUBSTRING_INDEX(SUBSTRING_INDEX(genres, '|', 1), '|', -1) as genre FROM movies\n","UNION\n","SELECT  SUBSTRING_INDEX(SUBSTRING_INDEX(genres, '|', 2), '|', -1) as genre FROM movies\n","UNION\n","SELECT  SUBSTRING_INDEX(SUBSTRING_INDEX(genres, '|', 3), '|', -1) as genre FROM movies\n","UNION\n","SELECT  SUBSTRING_INDEX(SUBSTRING_INDEX(genres, '|', 4), '|', -1) as genre FROM movies\n","UNION\n","SELECT  SUBSTRING_INDEX(SUBSTRING_INDEX(genres, '|', 5), '|', -1) as genre FROM movies\n","UNION\n","SELECT  SUBSTRING_INDEX(SUBSTRING_INDEX(genres, '|', 6), '|', -1) as genre FROM movies\n","ORDER BY genre;\n","\n","--This is method I do not like"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gGATBy16IsLF"},"outputs":[],"source":["from pyspark.sql.types import *\n","from pyspark.sql.functions import col, mean, udf, lit, current_timestamp, unix_timestamp, array_contains\n","extract_genres = udf(lambda x: x.split(\"|\"), ArrayType(StringType()))\n","movies_df_clean = movies_df.select(\"movieId\", \"title\", extract_genres(\"genres\").alias(\"genres\"))\n","#display(movies_df_clean)\n","\n","movies_df_clean.createOrReplaceTempView(\"movies_df_clean\")\n","\n","display (spark.sql(\"SELECT * FROM movies_df_clean limit 5\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2gmG0xEkIsLG"},"outputs":[],"source":["genres_result = list(set(movies_df_clean.select('genres').rdd.flatMap(tuple).flatMap(tuple).collect()))\n","genres_result"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"QahK-64HIsLG"},"source":["### Movie for Each Category"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"usVyKMdQIsLG"},"outputs":[],"source":["genres_result = list(set(movies_df_clean.select('genres').rdd.flatMap(tuple).flatMap(tuple).collect()))\n","genres_result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tZSbrRZMIsLH"},"outputs":[],"source":["movie_pdf = movies_df.toPandas()\n","movie_pdf['genres'].str.get_dummies(sep='|').head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"57i0nbRZIsLH"},"outputs":[],"source":["list_of_movie = list(movie_pdf['title'])"]},{"cell_type":"markdown","metadata":{"id":"T1a7TgtRIsLI"},"source":["## Part2: Spark ALS based approach for training model\n","We will use an Spark ML to predict the ratings, so let's reload \"ratings.csv\" using ``sc.textFile`` and then convert it to the form of (user, item, rating) tuples."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-O_S8tyeIsLI"},"outputs":[],"source":["#ratings_df.show(10)\n","\n","ratings_df.createOrReplaceTempView(\"ratings_df\")\n","\n","display (spark.sql(\"SELECT * FROM ratings_df limit 5\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hh5pE1OKIsLI"},"outputs":[],"source":["movie_ratings=ratings_df.drop('timestamp')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R_gBUzB6IsLI"},"outputs":[],"source":["# Data type convert\n","from pyspark.sql.types import IntegerType, FloatType\n","movie_ratings = movie_ratings.withColumn(\"userId\", movie_ratings[\"userId\"].cast(IntegerType()))\n","movie_ratings = movie_ratings.withColumn(\"movieId\", movie_ratings[\"movieId\"].cast(IntegerType()))\n","movie_ratings = movie_ratings.withColumn(\"rating\", movie_ratings[\"rating\"].cast(FloatType()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mtZ1CdlMIsLJ"},"outputs":[],"source":["#movie_ratings.show(10)\n","\n","movie_ratings.createOrReplaceTempView(\"movie_ratings\")\n","\n","display (spark.sql(\"SELECT * FROM movie_ratings limit 10\"))"]},{"cell_type":"markdown","metadata":{"id":"Sye9UbPCIsLJ"},"source":["### ALS Model Selection and Evaluation\n","\n","With the ALS model, we can use a grid search to find the optimal hyperparameters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BnJEFHKGIsLJ"},"outputs":[],"source":["# import package\n","from pyspark.ml.evaluation import RegressionEvaluator\n","from pyspark.ml.recommendation import ALS\n","from pyspark.ml.tuning import CrossValidator,ParamGridBuilder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wlveuCj7IsLK"},"outputs":[],"source":["#Create test and train set\n","(training,test)=movie_ratings.randomSplit([0.8,0.2])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-sz0RPXJIsLK"},"outputs":[],"source":["# Create ALS model\n","# Build the recommendation model using ALS on the training data\n","# Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n","als = ALS(maxIter=5, rank=10, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n","          coldStartStrategy=\"drop\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fT7aNsrwIsLK"},"outputs":[],"source":["# 1st print a list of parameters\n","print(als.explainParams())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"weFpjrdsIsLK"},"outputs":[],"source":["#Tune model using ParamGridBuilder\n","# it will take long time in the cv period, so just use few parameter to try \n","\n","paramGrid = (ParamGridBuilder()\n","             .addGrid(als.regParam, [0.01])\n","             .addGrid(als.rank, [10])\n","             .addGrid(als.maxIter, [15])\n","             .build())\n","\n","# paramGrid = (ParamGridBuilder()\n","#              .addGrid(als.regParam, [0.01, 0.5, 1, 1.5])\n","#              .addGrid(als.rank, [10, 15, 20, 25])\n","#              .addGrid(als.maxIter, [1, 5, 10, 15])\n","#              .build())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w18pnjFmIsLL"},"outputs":[],"source":["# Define evaluator as RMSE\n","\n","evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n","                                predictionCol=\"prediction\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_K13gvwkIsLL"},"outputs":[],"source":["from pyspark.ml.tuning import CrossValidator\n","# Build Cross validation \n","# Create 5-fold CrossValidator\n","# it takes too long that I only use 2-fold\n","cv = CrossValidator(estimator=als, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=2)\n","\n","# Run cross validations\n","cvModel = cv.fit(training)\n","# this will likely take a fair amount of time because of the amount of models that we're creating and testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_oFDPWObIsLL"},"outputs":[],"source":["# Extract the best model selected by CV\n","best_model = cvModel.bestModel"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C56IcU7KIsLM"},"outputs":[],"source":["#Fit ALS model to training data\n","\n","# specify parameter settings by the best model obtained via CV\n","print (\"**Best Model**\")\n","print (\"Rank: \", best_model)\n","print (\" MaxIter: \", str(best_model._java_obj.parent().getMaxIter()))\n","print (\" RegParam:\",  best_model._java_obj.parent().regParam())"]},{"cell_type":"markdown","metadata":{"id":"pd3hvWJmIsLM"},"source":["### Model testing\n","And finally, make a prediction and check the testing error."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i7bsYnfrIsLM"},"outputs":[],"source":["#Generate predictions and evaluate using RMSE\n","predictions=best_model.transform(test)\n","rmse = evaluator.evaluate(predictions)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":182},"executionInfo":{"elapsed":15,"status":"error","timestamp":1669913879509,"user":{"displayName":"Nikhil Dhumale","userId":"00177140792561608785"},"user_tz":-330},"id":"nPvQj-9-IsLM","outputId":"5e4927bf-8bae-4b2c-861a-00869e1a57f7"},"outputs":[],"source":["#Print RMSE \n","print (\"RMSE = \"+str(rmse))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eUZN7_KUIsLN"},"outputs":[],"source":["#Extract best model from the tuning exercise using ParamGridBuilder\n","\n","als_best = ALS(maxIter=15, rank=10, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n","          coldStartStrategy=\"drop\")\n","model = als_best.fit(training)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nehsSSGYIsLN"},"outputs":[],"source":["#predictions.show(10)\n","\n","predictions.createOrReplaceTempView(\"predictions\")\n","\n","display (spark.sql(\"SELECT * FROM predictions limit 10\"))"]},{"cell_type":"markdown","metadata":{"id":"ag3_LOovIsLO"},"source":["### Model apply and see the performance"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VlrGy5NbIsLO"},"outputs":[],"source":["alldata=best_model.transform(movie_ratings)\n","rmse = evaluator.evaluate(alldata)\n","print (\"RMSE = \"+str(rmse))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ySc5h7Q5IsLO"},"outputs":[],"source":["alldata.registerTempTable(\"alldata\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HICJOpFHIsLP"},"outputs":[],"source":["%sql SELECT * FROM alldata LIMIT 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z5WIvZEPIsLP"},"outputs":[],"source":["%sql SELECT * FROM movies JOIN alldata ON movies.movieId=alldata.movieId LIMIT 10"]},{"cell_type":"markdown","metadata":{"id":"CBefBdjyIsLP"},"source":["## Recommend moive to users with id: 575, 232. \n","you can choose some users to recommend the moives"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tqLlqi11IsLP"},"outputs":[],"source":["#recommend 10 movies for each users\n","user_recs = best_model.recommendForAllUsers(10)\n","#user_recs.show(10)\n","\n","user_recs.createOrReplaceTempView(\"user_recs\")\n","\n","display (spark.sql(\"SELECT * FROM user_recs limit 10\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a7zjeBxwIsLQ"},"outputs":[],"source":["user_recs.first()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XYGufW_CIsLQ"},"outputs":[],"source":["user_recs.registerTempTable(\"als_recs_temp\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h_xetLKSIsLR"},"outputs":[],"source":["# seperate the value of 'recommendations' in user_recs\n","\n","explode_rec = spark.sql('SELECT userId,\\\n","                                explode(recommendations) AS MovieRec\\\n","                                FROM als_recs_temp')\n","#explode_rec.show(10)\n","\n","\n","explode_rec.createOrReplaceTempView(\"explode_rec\")\n","\n","display (spark.sql(\"SELECT * FROM explode_rec limit 10\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4dnUrm3aIsLR"},"outputs":[],"source":["fianl_recs = spark.sql(\"SELECT userId,\\\n","                               movieIds_and_ratings.movieId AS movieId,\\\n","                               movieIds_and_ratings.rating AS prediction\\\n","                               FROM als_recs_temp\\\n","                               LATERAL VIEW explode(recommendations) exploded_table AS movieIds_and_ratings\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cL4ZcgOOIsLR"},"outputs":[],"source":["#fianl_recs.show(10)\n","\n","\n","fianl_recs.createOrReplaceTempView(\"fianl_recs\")\n","\n","display (spark.sql(\"SELECT * FROM fianl_recs limit 10\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WRV2MQWjIsLS"},"outputs":[],"source":["#Before we recommend the films, we need to filter out those users have not seen yet. Therefore, we need to choose rating = 'null' by join the movie ratings\n","\n","final_rec = fianl_recs.join(movie_ratings,['userId','movieId'],'left').filter(movie_ratings.rating.isNull())\n","#display(final_rec)\n","\n","final_rec.createOrReplaceTempView(\"final_rec\")\n","\n","display (spark.sql(\"SELECT * FROM final_rec LIMIT 5\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J9uZGMhkIsLS"},"outputs":[],"source":["final_rec.registerTempTable(\"final_rec\")\n","movies_df.registerTempTable(\"movies_df\")"]},{"cell_type":"markdown","metadata":{"id":"Gratk8rCIsLS"},"source":["### Find recommend films for userid = 575"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v3Buz3bCIsLT"},"outputs":[],"source":["%sql\n","SELECT userId,\n","       title\n","FROM final_rec t1\n","LEFT JOIN movies_df t2\n","ON t1.movieId = t2.movieId\n","WHERE t1.userId=575\n","LIMIT 10"]},{"cell_type":"markdown","metadata":{"id":"wv6-LNx2IsLT"},"source":["### Find recommend films for userid = 273"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ESCkWboXIsLT"},"outputs":[],"source":["%sql\n","SELECT userId,\n","       title\n","FROM final_rec t1\n","LEFT JOIN movies_df t2\n","ON t1.movieId = t2.movieId\n","WHERE t1.userId=273\n","LIMIT 5"]},{"cell_type":"markdown","metadata":{"id":"Vf4DaOqtIsLT"},"source":["## Find the similar moives for moive with id: 463, 471\n","You can find the similar moives based on the ALS results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pCMA98qiIsLT"},"outputs":[],"source":["# 1st extract productFeatures matrix\n","# The productFeatures matrix will be used to create an item-item collaborative filtering recommendation model\n","from pyspark.mllib.recommendation import ALS\n","import math\n","\n","model_a = ALS.train(movie_ratings, rank=10, iterations=15,\n","                      lambda_=0.01)\n","model_a.productFeatures().count()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TsWPID7pIsLU"},"outputs":[],"source":["# look at the feature vector of movie 463\n","movie_feature = model_a.productFeatures().lookup(471)[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tTxIXPNVIsLU"},"outputs":[],"source":["# Next define cosine similarity function to measure movie similarity\n","def cosineSimilarity(vec1, vec2):\n","  return vec1.dot(vec2) / (LA.norm(vec1) * LA.norm(vec2))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EoAEoaeWIsLU"},"outputs":[],"source":["# Assigns the movies title file\n","movies_file = os.path.join(\"/FileStore/tables/\", 'movies.csv')\n","movies_sc = sc.textFile(movies_file)\n","\n","movies_sc_header = movies_sc.take(1)[0]\n","\n","movies_data = movies_sc.filter(lambda line: line!=movies_sc_header)\\\n","    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1])).cache()\n","\n","movies_titles = movies_data.map(lambda x: (int(x[0]),x[1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LVOWUWAbIsLU"},"outputs":[],"source":["movies_sc_header"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lr2IcqlSIsLV"},"outputs":[],"source":["movies_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5KaRJ7o9IsLV"},"outputs":[],"source":["movies_titles"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w0hkxHBNIsLV"},"outputs":[],"source":["# Build similarity matrix for movieid 471 using the product features matrix\n","\n","similarMovies = model_a.productFeatures().map(lambda products:(products[0],\n","                                        cosineSimilarity(np.asarray(products[1]), movie_feature))).join(movies_titles).map(lambda r: (r[1][1], r[1][0], r[0]))\n","\n","# Sort the top 10 most similar movies descendingly by cosine similarity measure\n","# similarMovies.takeOrdered(11, key=lambda x: -x[1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i-zgZCORIsLW"},"outputs":[],"source":["from pyspark.ml.linalg import Vectors\n","from pyspark.sql.functions import col\n","from pyspark.ml.feature import BucketedRandomProjectionLSH\n","from pyspark.ml.linalg import Vectors, VectorUDT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i-PRs9AbIsLW"},"outputs":[],"source":["a = best_model.itemFactors\n","# display(a.cache())\n","\n","a.createOrReplaceTempView(\"a\")\n","\n","display (spark.sql(\"SELECT * FROM a limit 5\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o2ODsDnNIsLW"},"outputs":[],"source":["a.registerTempTable(\"movie_on_movie\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nj8Y2GjOIsLW"},"outputs":[],"source":["%sql\n","SELECT features FROM movie_on_movie WHERE id = 471"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T-mMX87MIsLX"},"outputs":[],"source":["%sql\n","SELECT * FROM ratings WHERE movieId = 463 LIMIT 10"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EdDtJPvVIsLX"},"outputs":[],"source":["brp = BucketedRandomProjectionLSH(inputCol=\"features\", outputCol=\"hashes\",seed=12345, bucketLength=1.0)\n","#a.printSchema()\n","#change features columns into dense vector\n","to_vector = udf(lambda a: Vectors.dense(a), VectorUDT())\n","data = a.select(\"id\", to_vector(\"features\").alias(\"features\"))\n","#data.printSchema()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5TNOC_6JIsLX"},"outputs":[],"source":["model = brp.fit(data)\n","model.transform(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F2l8HDm6IsLY"},"outputs":[],"source":["model.approxNearestNeighbors(data, Vectors.dense([-0.73946416, -1.03179, -0.83905196, -0.6525196, -0.3816911, -0.88358724, -0.47698575, -0.15836999, 0.36126232, -0.6475737]), 6).collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"snkonIuoIsLY"},"outputs":[],"source":["# similar moives for moive with id: 471"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OAZjPN3yIsLY"},"outputs":[],"source":["%sql\n","SELECT * FROM movies\n","WHERE movieId IN (6296,97057,3476,1059,4346)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3dMRMUaKIsLY"},"outputs":[],"source":["%sql\n","SELECT features FROM movie_on_movie WHERE id = 463"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f-pFfID4IsLZ"},"outputs":[],"source":["model.approxNearestNeighbors(data, Vectors.dense([0.93929714, 0.015614069, -0.3408886, 0.3818301, 0.19762212, -1.4255825, 0.99496984, -0.065754086, 0.43202916, -0.8621043]), 6).collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"97BGPUCWIsLZ"},"outputs":[],"source":["# similar moives for moive with id: 463"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d-H9fDcvIsLZ"},"outputs":[],"source":["%sql\n","SELECT * FROM movies\n","WHERE movieId IN (5321,49007,554,7276,7224)"]},{"cell_type":"markdown","metadata":{"id":"y859l9SWIsLZ"},"source":["Based on the above, we obtain the 5 movies that are most similar to movie with id: 471. They are:\n","William Shakespeare's Romeo + Juliet (1996),\n","\"Jacob's Ladder (1990)',\n","'Bride of the Wind (2001)',\n","'Stop Making Sense (1984)',\n","'Mighty Wind, A (2003)',\n","'Kon-Tiki (2012)'."]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"kpp6I6SHIsLa"},"source":[]}],"metadata":{"colab":{"collapsed_sections":["DxzIgU0wIsLB","0lgzHfPmIsLC","IKGptyZ9IsLE","1jk9n3wuIsLE","QahK-64HIsLG","T1a7TgtRIsLI","Sye9UbPCIsLJ","pd3hvWJmIsLM","ag3_LOovIsLO","CBefBdjyIsLP","Gratk8rCIsLS","wv6-LNx2IsLT","Vf4DaOqtIsLT","kpp6I6SHIsLa"],"provenance":[{"file_id":"1g26r5UUagk7gvU9JFwScuCcCgkzVJ5GS","timestamp":1669903751241}]},"kernelspec":{"display_name":"Python 3.11.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":"2"},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"},"name":"Movie Recommendation Engine in Apache Spark","notebookId":2964997303881322,"vscode":{"interpreter":{"hash":"1f6a27bcfbe46a917dbd192f4a82657396dda26148bae633192e8d28c70725f1"}}},"nbformat":4,"nbformat_minor":0}
